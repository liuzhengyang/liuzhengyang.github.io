(window.webpackJsonp=window.webpackJsonp||[]).push([[96],{527:function(e,t,a){"use strict";a.r(t);var r=a(34),s=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"consistent-core"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#consistent-core"}},[e._v("#")]),e._v(" consistent core")]),e._v(" "),a("h2",{attrs:{id:"问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#问题"}},[e._v("#")]),e._v(" 问题")]),e._v(" "),a("p",[e._v("当一个集群需要处理非常多的数据的时候，就需要更多的server机器。\n这些机器有一些通用的需求，比如选择一个server作为一些任务的master，管理群组成员信息、\n处理数据分片到server的映射等。这些需求需要强一致性保证，也称为「线性一致性」linearizability。\n对应的实现需要容忍错误（fault tolerant)。\n通常的做法是使用一个fault tolerant的基于quorum（半数以上协议）一致性算法。\n但是在基于quorum的系统中，吞吐会随着cluster的实例数量变大而降低（需要更多的机器通信达成一致）")]),e._v(" "),a("h2",{attrs:{id:"解决方案"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解决方案"}},[e._v("#")]),e._v(" 解决方案")]),e._v(" "),a("p",[e._v("实现一个小的3-5个节点的集群，来提供线性一致性保证，同时能够容忍故障(fault tolerance)。\n然后单独的数据集群就可以使用这个小的一致性集群来管理metadata(元数据)以及做集群维度的决定通过Lease（租约）这样的机制。\n这样，数据集群就能增长到非常多的server，但是只需要使用很小的元数据集群来提供强一致性保证。")]),e._v(" "),a("p",[a("img",{staticClass:"lazy",attrs:{alt:"img.png","data-src":"data-cluster-consistent-core.png",loading:"lazy"}})]),e._v(" "),a("p",[e._v("一致性核心core模块通常提供下面的接口")]),e._v(" "),a("div",{staticClass:"language-text line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("public interface ConsistentCore {\n    CompletableFuture put(String key, String value);\n\n    List&lt;String> get(String keyPrefix);\n\n    CompletableFuture registerLease(String name, long ttl);\n\n    void refreshLease(String name);\n\n    void watch(String name, Consumer&lt;WatchEvent> watchCallback);\n}\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br")])]),a("h2",{attrs:{id:"元数据存储"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#元数据存储"}},[e._v("#")]),e._v(" 元数据存储")]),e._v(" "),a("p",[e._v("元数据存储使用像raft这样的一致性算法，raft是一种Replicated Write Ahead Log实现，通过Leader and Follower模式实现复制，\n通过High-Water Mark模式跟踪被quorum成功复制的数据。")]),e._v(" "),a("h3",{attrs:{id:"层级存储"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#层级存储"}},[e._v("#")]),e._v(" 层级存储")]),e._v(" "),a("p",[e._v("metadata的key value存储，通常会使用逻辑上的层级结构，比如/servers/1, /servers/2，表达类似目录的概念。")]),e._v(" "),a("h2",{attrs:{id:"客户端交互"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#客户端交互"}},[e._v("#")]),e._v(" 客户端交互")]),e._v(" "),a("p",[e._v("客户端和consistent core的交互协议。")]),e._v(" "),a("h3",{attrs:{id:"查找leader"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查找leader"}},[e._v("#")]),e._v(" 查找leader")]),e._v(" "),a("p",[e._v("查找leader，所有的操作都要在leader上完成，所以client类库需要先找到leader server。")]),e._v(" "),a("p",[e._v("有两种方式")]),e._v(" "),a("ul",[a("li",[e._v("follower知道当前的leader，所以如果client连接到了follower上，follower会返回给client当前的leader地址，client再连接到leader发送请求。")]),e._v(" "),a("li",[e._v("server实现请求转发机器，follower把请求转发给leader。")])]),e._v(" "),a("h3",{attrs:{id:"处理重复请求"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#处理重复请求"}},[e._v("#")]),e._v(" 处理重复请求")]),e._v(" "),a("p",[e._v("client发现请求超时后，一定条件下要进行重试，而之前超时的请求有可能已经被server成功处理了。\n所以需要一种机制能够处理这种重复的请求，幂等处理是一种实现重复检测的模式。")])])}),[],!1,null,null,null);t.default=s.exports}}]);